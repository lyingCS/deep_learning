{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回忆一下，3.8节（多层感知机）的图3.3描述了一个单隐藏层的多层感知机。其中输入个数为4，隐藏单元个数为5，且隐藏单元$h_i$（$i=1, \\ldots, 5$）的计算表达式为\n",
    "\n",
    "$$ h_i = \\phi\\left(x_1 w_{1i} + x_2 w_{2i} + x_3 w_{3i} + x_4 w_{4i} + b_i\\right) $$\n",
    "\n",
    "这里$\\phi$是激活函数，$x_1, \\ldots, x_4$是输入，隐藏单元$i$的权重参数为$w_{1i}, \\ldots, w_{4i}$，偏差参数为$b_i$。当对该隐藏层使用丢弃法时，该层的隐藏单元将有一定概率被丢弃掉。设丢弃概率为$p$，那么有$p$的概率$h_i$会被清零，有$1-p$的概率$h_i$会除以$1-p$做拉伸。丢弃概率是丢弃法的超参数。具体来说，设随机变量$\\xi_i$为0和1的概率分别为$p$和$1-p$。使用丢弃法时我们计算新的隐藏单元$h_i'$\n",
    "\n",
    "$$ h_i' = \\frac{\\xi_i}{1-p} h_i $$\n",
    "\n",
    "由于$E(\\xi_i) = 1-p$，因此\n",
    "\n",
    "$$ E(h_i') = \\frac{E(\\xi_i)}{1-p}h_i = h_i $$\n",
    "\n",
    "即丢弃法不改变其输入的期望值。让我们对图3.3中的隐藏层使用丢弃法，一种可能的结果如图3.5所示，其中$h_2$和$h_5$被清零。这时输出值的计算不再依赖$h_2$和$h_5$，在反向传播时，与这两个隐藏单元相关的权重的梯度均为0。由于在训练中隐藏层神经元的丢弃是随机的，即$h_1, \\ldots, h_5$都有可能被清零，输出层的计算无法过度依赖$h_1, \\ldots, h_5$中的任一个，从而在训练模型时起到正则化的作用，并可以用来应对过拟合。在测试模型时，我们为了拿到更加确定性的结果，一般不使用丢弃法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T23:11:09.034792Z",
     "start_time": "2020-08-06T23:10:50.045950Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import d2lzh_pytorch as d2l\n",
    "\n",
    "def dropout(X,drop_prob):\n",
    "    X=X.float()\n",
    "    assert 0<=drop_prob<=1\n",
    "    keep_prob=1-drop_prob\n",
    "    if keep_prob==0:\n",
    "        return torch.zeros_like(X)\n",
    "    mask=(torch.rand(X.shape)<keep_prob).float()\n",
    "    return mask*X/keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T23:11:13.711206Z",
     "start_time": "2020-08-06T23:11:13.550397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11., 12., 13., 14., 15.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.arange(16).view(2,8)\n",
    "dropout(X,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T23:11:32.778040Z",
     "start_time": "2020-08-06T23:11:32.765525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  2.,  4.,  6.,  8., 10.,  0.,  0.],\n",
       "        [ 0.,  0., 20.,  0., 24.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout(X,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T23:12:18.625051Z",
     "start_time": "2020-08-06T23:12:18.606829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout(X,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T23:21:55.752921Z",
     "start_time": "2020-08-06T23:21:55.715329Z"
    }
   },
   "outputs": [],
   "source": [
    "num_inputs,num_outputs,num_hiddens1,num_hiddens2=784,10,256,256\n",
    "W1=torch.tensor(np.random.normal(0,0.01,size=(num_inputs,num_hiddens1)),dtype=torch.float,requires_grad=True)\n",
    "b1=torch.zeros(num_hiddens1,requires_grad=True)\n",
    "W2=torch.tensor(np.random.normal(0,0.01,size=(num_hiddens1,num_hiddens2)),dtype=torch.float,requires_grad=True)\n",
    "b2=torch.zeros(num_hiddens2,requires_grad=True)\n",
    "W3=torch.tensor(np.random.normal(0,0.01,size=(num_hiddens2,num_outputs)),dtype=torch.float,requires_grad=True)\n",
    "b3=torch.zeros(num_outputs,requires_grad=True)\n",
    "\n",
    "params=[W1,b1,W2,b2,W3,b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T00:29:38.701261Z",
     "start_time": "2020-08-07T00:29:38.685042Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_prob1,drop_prob2=0.2,0.5\n",
    "\n",
    "def net(X,is_training=True):\n",
    "    X=X.view(-1,num_inputs)\n",
    "    H1=(torch.matmul(X,W1)+b1).relu()\n",
    "    if is_training:\n",
    "        H1=dropout(H1,drop_prob1)\n",
    "    H2=(torch.matmul(H1,W2)+b2).relu()\n",
    "    if is_training:\n",
    "        H2-dropout(H2,drop_prob2)\n",
    "    return torch.matmul(H2,W3)+b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T00:29:39.349023Z",
     "start_time": "2020-08-07T00:29:39.333257Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter,net):\n",
    "    acc_sum=0.0,0\n",
    "    for X,y in data_iter:\n",
    "        if isinstance(net,torch.nn.Module):\n",
    "            net.eval()\n",
    "            acc_sum+=(net(X).argmax(dim=1)==y).float().sum().item()\n",
    "            net.train()\n",
    "        else:\n",
    "            if('is_training' in net.__code__.co_varnames):\n",
    "                acc_sum+=(net(X,is_training=False).argmax(dim=1)==y).float().sum().item()\n",
    "            else:\n",
    "                acc_sum+=(net(X).argmax(dim=1)==y).float(),sum().item()\n",
    "        n+=y.shape[0]\n",
    "    return acc_sum/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T00:31:25.148223Z",
     "start_time": "2020-08-07T00:29:40.119717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0045, train acc 0.545, test acc 0.689\n",
      "epoch 2, loss 0.0022, train acc 0.786, test acc 0.787\n",
      "epoch 3, loss 0.0018, train acc 0.828, test acc 0.837\n",
      "epoch 4, loss 0.0017, train acc 0.843, test acc 0.837\n",
      "epoch 5, loss 0.0015, train acc 0.855, test acc 0.823\n"
     ]
    }
   ],
   "source": [
    "num_epochs,lr,batch_size=5,100.0,256\n",
    "loss=torch.nn.CrossEntropyLoss()\n",
    "train_iter,test_iter=d2l.load_data_fashion_mnist(batch_size)\n",
    "d2l.train_ch3(net,train_iter,test_iter,loss,num_epochs,batch_size,params,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T00:32:44.304709Z",
     "start_time": "2020-08-07T00:32:44.265499Z"
    }
   },
   "outputs": [],
   "source": [
    "net=nn.Sequential(\n",
    "    d2l.FlattenLayer(),\n",
    "    nn.Linear(num_inputs,num_hiddens1),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(drop_prob1),\n",
    "    nn.Linear(num_hiddens1,num_hiddens2),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(drop_prob2),\n",
    "    nn.Linear(num_hiddens2,10)\n",
    ")\n",
    "\n",
    "for param in net.parameters():\n",
    "    nn.init.normal_(param,mean=0,std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-07T00:35:44.660354Z",
     "start_time": "2020-08-07T00:34:06.165759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0047, train acc 0.535, test acc 0.693\n",
      "epoch 2, loss 0.0023, train acc 0.777, test acc 0.770\n",
      "epoch 3, loss 0.0020, train acc 0.818, test acc 0.785\n",
      "epoch 4, loss 0.0018, train acc 0.834, test acc 0.811\n",
      "epoch 5, loss 0.0017, train acc 0.845, test acc 0.814\n"
     ]
    }
   ],
   "source": [
    "optimizer=torch.optim.SGD(net.parameters(),lr=0.5)\n",
    "d2l.train_ch3(net,train_iter,test_iter,loss,num_epochs,batch_size,None,None,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
